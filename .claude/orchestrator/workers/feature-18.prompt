You are a worker agent focused on implementing a single feature.

## Your Task
Provider 18: OpenAI Realtime API - Extend OpenAI provider for real-time voice conversation API

## Orchestration Context
Implement 18 AI provider SDKs with zero dependencies, 90%+ test coverage, and programmatic validation enforcement.

## Providers to Implement (Tier 2)
1. ElevenLabs TTS - text-to-speech with voice cloning
2. Deepgram STT - live streaming transcription
3. OpenAI Whisper - audio transcription extension
4. OpenAI TTS - text-to-speech extension
5. PlayHT - ultra-realistic TTS
6. Luma AI Video - Dream Machine video generation
7. Runway ML - Gen-2 video generation
8. OpenAI Extended - refactor to use internal HTTP client
9. Anthropic Extended Thinking - extended thinking mode
10. Google Gemini Thinking - thinking modes
11. DeepSeek Extended - refactor to use internal HTTP client
12. Cerebras Extended - refactor to use internal HTTP client
13. FAL Extended - refactor to use internal HTTP client
14. Midjourney - V6 text-to-image
15. OpenAI Embeddings - embeddings extension
16. Cohere Embeddings - embed-english-v3.0
17. Voyage AI - embeddings provider
18. OpenAI Realtime API - real-time voice conversation

## Requirements
- Zero external dependencies (pure Go stdlib)
- 90%+ test coverage (enforced by validation script)
- Use internal/http client (no external SDKs)
- Pass all 7 validation gates (build, test, coverage, race, vet, fmt, interface)
- Workers MUST use bash scripts/swarm-mark-complete.sh to mark complete

## Project Context Files
### From CLAUDE.md:
# ModelScan Project Instructions

## Identity
Development partner for ModelScan - 21 production-ready Go SDKs for LLM providers with zero dependencies.

## Sacred Rules
1. Never guess - read files before answering, investigate before claims
2. Never create files unless necessary - prefer editing existing
3. Never claim "done" without running validation
4. Never suppress warnings to avoid fixing issues
5. Never touch production/main without explicit approval
6. Never commit secrets, API keys, or credentials
7. Never add external dependencies - maintain 100% stdlib

## Validation

Run after EVERY code change:
```bash
# Quick (while iterating)
go build ./... && go vet ./...

# Full (before marking complete)
go test ./... -race -coverprofile=coverage.out
```

Mark complete ONLY when validation passes with actual output shown.

## Workflow (Geoffrey Pattern)
1. UNDERSTAND - Read relevant files first (no code yet)
2. IMPLEMENT - Make changes
3. VALIDATE - Run checks
4. ITERATE - Fix issues until clean
5. COMPLETE - Only when validation passes

## Codebase Structure
```
modelscan/
├── sdk/                      # 21 Production SDKs
│   ├── openai/              # OpenAI SDK
│   ├── anthropic/           # Anthropic SDK
│   ├── google/              # Google Gemini SDK
│   ├── mistral/             # Mistral SDK
│   ├── groq/                # Groq SDK
│   ├── together/            # Together AI SDK
│   ├── fireworks/           # Fireworks SDK
│   ├── deepseek/            # DeepSeek SDK
│   ├── replicate/           # Replicate SDK
│   ├── cohere/              # Cohere SDK
│   ├── perplexity/          # Perplexity SDK
│   ├── deepinfra/           # DeepInfra SDK
│   ├── hyperbolic/          # Hyperbolic SDK
│   ├── xai/                 # xAI SDK
│   ├── minimax/             # Minimax SDK
│   ├── kimi/                # Kimi SDK
│   ├── zai/                 # Z.AI SDK
│   ├── openrouter/          # OpenRouter SDK
│   ├── synthetic/           # Synthetic SDK
│   ├── vibe/                # Vibe SDK
│   └── nanogpt/             # NanoGPT SDK
│
├── examples/                # Working examples
│   ├── basic/              # Simple usage
│   ├── multi-provider/     # Provider comparison
│   └── unified/            # Unified SDK usage
│
├── .claude/                # Project-specific Claude config
│   ├── hooks/              # Protection hooks
│   ├── skills/             # On-demand skills
│   ├── memory/             # Session memory
│   └── optimizations/      # Token optimization
│
├── Makefile                # Build automation
├── test-all-sdks.sh       # Test orchestration
└── CLAUDE.md              # This file
```

## Key Patterns
- Each SDK is independent with own go.mod
- Zero external dependencies (pure stdlib)
- Consistent APIs across all providers
- Production-ready error handling
- Context threading for cancellation

## Hooks & Protections
Protection hooks in `.claude/hooks/`:
- `bash-protection.cjs` - Blocks destructive commands
- `antipattern-detector.cjs` - Catches stub implementations
- `suppression-abuse-detector.cjs` - Prevents hiding issues

## Skills (On-Demand)
Load from `.claude/skills/` when needed:
- `verification-before-completion/` - Completion protocol
- `systematic-debugging/` - Four-phase debugging

## Token Optimization
Directives in `.claude/optimizations/`:
- `haiku-explore.md` - Model selection guidelines
- `targeted-reads.md` - Surgical file reads
- `batched-edits.md` - Change batching strategy

## Memory
- Session diaries: `.claude/memory/diary/`
- Reflections: `.claude/memory/REFLECTIONS.md`
- claude-mem MCP server provides persistent cross-session memory

## MCP Servers

### Integrated MCP Servers
ModelScan supports Model Context Protocol (MCP) servers for extended functionality:

**Active:**
- `claude-mem` - Persistent cross-session memory and observations
- `ydc-server` - You.com web search and content extraction
- `claude-swarm` - Multi-agent orchestration and parallel workers

**Recommended:**
- **Context-Engine** 
... (truncated)


## Implementation Steps (REQUIRED)

### Phase 1: Get Your Bearings (ALWAYS START HERE)
1. Run 'pwd' to see your working directory
2. Read git logs: 'git log --oneline -20' to see recent work
3. Read claude-progress.txt (if it exists) to understand what was recently done
4. Read the feature list to understand overall progress
5. If init.sh exists, read it to understand how to run/test the project

### Phase 2: Verify Environment Health
1. Run basic tests or start development server (if applicable)
2. Verify the codebase is in a working state
3. If broken, fix critical bugs BEFORE implementing your feature
4. Document any fixes in your .done file

### Phase 3: Implement Your Feature
1. Read the relevant source files to understand current implementation
2. Make the necessary code changes using Edit or Write tools
3. Test your changes thoroughly:
   - Run automated tests (unit, integration)
   - For web features: Use Chrome DevTools MCP to test in browser as a user would
   - Verify syntax, check behavior end-to-end
   - Take screenshots of working features if applicable
4. ONLY AFTER code changes are complete AND tested: Create .claude/orchestrator/workers/feature-18.done

   The .done file MUST contain:
   - List of files you modified (with line numbers if applicable)
   - Summary of changes made to each file
   - Any tests you ran and their results
   - If BLOCKED: explain what blocked you and what you tried

### Phase 4: Leave Environment Clean
1. Do NOT commit - the orchestrator handles commits
2. Ensure all tests pass
3. Ensure code is in a working state for the next worker

## Critical Requirements
- You MUST make actual code changes - reading files is not enough
- You MUST use Edit/Write tools to modify source code
- Do NOT create the .done file until you have modified code
- If you encounter a blocker, document it in .done and explain what prevented completion
- Keep changes minimal and focused on this single feature
- NEVER commit, stage, or git add ANY of these files:
  - .claude/ (entire directory - orchestrator state, logs, prompts, worker files)
  - claude-progress.txt
  - init.sh
  - *.prompt, *.log, *.done, *.status files in .claude/


## Additional Context
# Provider: OpenAI Realtime API

## Mission
Extend OpenAI provider for real-time voice API with 90%+ coverage.

## Validation
```bash
bash /home/agent/modelscan/scripts/validate-provider.sh realtime 90
bash /home/agent/modelscan/scripts/swarm-mark-complete.sh feature-18 realtime
```

## Implementation
Files: `providers/realtime.go`, `providers/realtime_test.go`

### OpenAI Realtime API
- WebSocket: wss://api.openai.com/v1/realtime
- Models: gpt-4o-realtime-preview
- Voice conversation (bidirectional)

**90% exact. FINAL FEATURE!**

Begin implementing the feature now.