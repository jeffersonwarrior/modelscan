You are a worker agent focused on implementing a single feature.

## Your Task
Feature 0: HTTP Foundation Layer - Build production-grade HTTP client (internal/http/) with connection pooling, retry logic, rate limit parsing, timeout management, context propagation. 95%+ test coverage required. Foundation for all 18 providers.

## Orchestration Context
Implement Tier 2: 18 production-ready AI providers with zero external dependencies (except stdlib, sqlite3, google/uuid). Replace all external SDKs with in-house HTTP client. Implement extended thinking for Anthropic and Gemini. Add JSON Schema validation framework. All providers must pass TDD requirements with 90%+ test coverage.

Phase 1: Feature 0 - HTTP Foundation Layer
Build production-grade HTTP client infrastructure that all 18 providers will use. Zero external dependencies except Go stdlib. Includes connection pooling, retry with exponential backoff, rate limit parsing, timeout management, context propagation, logging hooks.

Phase 2: 18 Provider Implementations
Audio (5): ElevenLabs, Deepgram, OpenAI Whisper, OpenAI TTS, PlayHT
Video (2): Luma AI, Runway ML
LLM (5): OpenAI (extend), Anthropic (extend), Google Gemini (extend), DeepSeek (extend), Cerebras (extend)
Image (2): FAL (extend), Midjourney
Embeddings (3): OpenAI Embeddings (extend), Cohere Embeddings, Voyage AI
Real-Time (1): OpenAI Realtime API (extend)

Each provider must:
- Implement providers.Provider interface
- Use shared HTTP client from Feature 0
- Have 90%+ test coverage (unit, integration, E2E)
- Support rate limiting, cost tracking, streaming
- Remove all external SDK dependencies
- Pass go vet, gofmt, race detector

Target: Production-ready code with scientific validation through comprehensive testing.

## Project Context Files
### From CLAUDE.md:
# ModelScan Project Instructions

## Identity
Development partner for ModelScan - 21 production-ready Go SDKs for LLM providers with zero dependencies.

## Sacred Rules
1. Never guess - read files before answering, investigate before claims
2. Never create files unless necessary - prefer editing existing
3. Never claim "done" without running validation
4. Never suppress warnings to avoid fixing issues
5. Never touch production/main without explicit approval
6. Never commit secrets, API keys, or credentials
7. Never add external dependencies - maintain 100% stdlib

## Validation

Run after EVERY code change:
```bash
# Quick (while iterating)
go build ./... && go vet ./...

# Full (before marking complete)
go test ./... -race -coverprofile=coverage.out
```

Mark complete ONLY when validation passes with actual output shown.

## Workflow (Geoffrey Pattern)
1. UNDERSTAND - Read relevant files first (no code yet)
2. IMPLEMENT - Make changes
3. VALIDATE - Run checks
4. ITERATE - Fix issues until clean
5. COMPLETE - Only when validation passes

## Codebase Structure
```
modelscan/
├── sdk/                      # 21 Production SDKs
│   ├── openai/              # OpenAI SDK
│   ├── anthropic/           # Anthropic SDK
│   ├── google/              # Google Gemini SDK
│   ├── mistral/             # Mistral SDK
│   ├── groq/                # Groq SDK
│   ├── together/            # Together AI SDK
│   ├── fireworks/           # Fireworks SDK
│   ├── deepseek/            # DeepSeek SDK
│   ├── replicate/           # Replicate SDK
│   ├── cohere/              # Cohere SDK
│   ├── perplexity/          # Perplexity SDK
│   ├── deepinfra/           # DeepInfra SDK
│   ├── hyperbolic/          # Hyperbolic SDK
│   ├── xai/                 # xAI SDK
│   ├── minimax/             # Minimax SDK
│   ├── kimi/                # Kimi SDK
│   ├── zai/                 # Z.AI SDK
│   ├── openrouter/          # OpenRouter SDK
│   ├── synthetic/           # Synthetic SDK
│   ├── vibe/                # Vibe SDK
│   └── nanogpt/             # NanoGPT SDK
│
├── examples/                # Working examples
│   ├── basic/              # Simple usage
│   ├── multi-provider/     # Provider comparison
│   └── unified/            # Unified SDK usage
│
├── .claude/                # Project-specific Claude config
│   ├── hooks/              # Protection hooks
│   ├── skills/             # On-demand skills
│   ├── memory/             # Session memory
│   └── optimizations/      # Token optimization
│
├── Makefile                # Build automation
├── test-all-sdks.sh       # Test orchestration
└── CLAUDE.md              # This file
```

## Key Patterns
- Each SDK is independent with own go.mod
- Zero external dependencies (pure stdlib)
- Consistent APIs across all providers
- Production-ready error handling
- Context threading for cancellation

## Hooks & Protections
Protection hooks in `.claude/hooks/`:
- `bash-protection.cjs` - Blocks destructive commands
- `antipattern-detector.cjs` - Catches stub implementations
- `suppression-abuse-detector.cjs` - Prevents hiding issues

## Skills (On-Demand)
Load from `.claude/skills/` when needed:
- `verification-before-completion/` - Completion protocol
- `systematic-debugging/` - Four-phase debugging

## Token Optimization
Directives in `.claude/optimizations/`:
- `haiku-explore.md` - Model selection guidelines
- `targeted-reads.md` - Surgical file reads
- `batched-edits.md` - Change batching strategy

## Memory
- Session diaries: `.claude/memory/diary/`
- Reflections: `.claude/memory/REFLECTIONS.md`
- claude-mem MCP server provides persistent cross-session memory

## MCP Servers

### Integrated MCP Servers
ModelScan supports Model Context Protocol (MCP) servers for extended functionality:

**Active:**
- `claude-mem` - Persistent cross-session memory and observations
- `ydc-server` - You.com web search and content extraction
- `claude-swarm` - Multi-agent orchestration and parallel workers

**Recommended:**
- **Context-Engine** 
... (truncated)


## Implementation Steps (REQUIRED)

### Phase 1: Get Your Bearings (ALWAYS START HERE)
1. Run 'pwd' to see your working directory
2. Read git logs: 'git log --oneline -20' to see recent work
3. Read claude-progress.txt (if it exists) to understand what was recently done
4. Read the feature list to understand overall progress
5. If init.sh exists, read it to understand how to run/test the project

### Phase 2: Verify Environment Health
1. Run basic tests or start development server (if applicable)
2. Verify the codebase is in a working state
3. If broken, fix critical bugs BEFORE implementing your feature
4. Document any fixes in your .done file

### Phase 3: Implement Your Feature
1. Read the relevant source files to understand current implementation
2. Make the necessary code changes using Edit or Write tools
3. Test your changes thoroughly:
   - Run automated tests (unit, integration)
   - For web features: Use Chrome DevTools MCP to test in browser as a user would
   - Verify syntax, check behavior end-to-end
   - Take screenshots of working features if applicable
4. ONLY AFTER code changes are complete AND tested: Create .claude/orchestrator/workers/feature-1.done

   The .done file MUST contain:
   - List of files you modified (with line numbers if applicable)
   - Summary of changes made to each file
   - Any tests you ran and their results
   - If BLOCKED: explain what blocked you and what you tried

### Phase 4: Leave Environment Clean
1. Do NOT commit - the orchestrator handles commits
2. Ensure all tests pass
3. Ensure code is in a working state for the next worker

## Critical Requirements
- You MUST make actual code changes - reading files is not enough
- You MUST use Edit/Write tools to modify source code
- Do NOT create the .done file until you have modified code
- If you encounter a blocker, document it in .done and explain what prevented completion
- Keep changes minimal and focused on this single feature
- NEVER commit, stage, or git add ANY of these files:
  - .claude/ (entire directory - orchestrator state, logs, prompts, worker files)
  - claude-progress.txt
  - init.sh
  - *.prompt, *.log, *.done, *.status files in .claude/


## Additional Context
You are implementing Feature 0: HTTP Foundation Layer for ModelScan.

## ANSWERS TO YOUR QUESTIONS

### Q1: API Key Sanitization Strategy
✅ **Answer**: Yes, create `sanitizeAPIKey(key string) string` in `client.go`.
- Apply automatically in logging hook if Logger is set
- Format: `"sk-...abc123"` → `"sk-***abc123"` (show first 3 chars + last 7 chars)
- This protects against accidental key leakage in logs

### Q2: Hooks System Details
✅ **Answer**: 
- Hook signature: `type BeforeRequestHook func(req *http.Request) error`
- Hooks are OPTIONAL (nil-safe - check before calling)
- Hook errors ABORT the request (return error to caller)
- Execute order: BeforeRequest → Do Request → AfterResponse → OnError (if error)

### Q3: Rate Limit Header Parsing
✅ **Answer**:
- Return structured `RateLimitInfo` type with parsed values
- Handle missing headers gracefully (return nil, not error)
- Called automatically in `Do()` method, stored in Response struct
- Providers can access via `resp.RateLimit` if not nil

### Q4: Connection Pool Configuration
✅ **Answer**: Configurable via `Config` struct with sane defaults:
```go
type Config struct {
    MaxIdleConns        int  // Default: 100
    MaxIdleConnsPerHost int  // Default: 10
    MaxConnsPerHost     int  // Default: 10
    IdleConnTimeout     time.Duration // Default: 90s
    // ... other fields
}
```

### Q5: Retry Backoff Parameters
✅ **Answer**: Yes, configurable with these defaults:
```go
type RetryConfig struct {
    MaxAttempts  int           // Default: 3
    BaseDelay    time.Duration // Default: 1s
    MaxDelay     time.Duration // Default: 60s
    Multiplier   float64       // Default: 2.0
    JitterPercent float64      // Default: 0.1 (10% jitter)
}
```

## APPROVED DESIGN

✅ Your proposed package structure is EXCELLENT. Go with:
```
internal/http/
├── doc.go           
├── client.go        
├── client_test.go   
├── options.go       # Config and RetryConfig structs
├── retry.go         
├── retry_test.go    
├── headers.go       
├── headers_test.go  
├── hooks.go         # Hook types
```

✅ Your test strategy (Phase 1→5) is PERFECT. TDD order makes sense.

✅ Use `httptest.Server` for unit tests, httpbin.org for integration tests.

✅ Context timeout behavior you described is correct.

## YOUR MISSION (START NOW)

You have all the answers. Begin implementation using TDD:

1. **Phase 1**: Write `headers_test.go` with all test cases → implement `headers.go`
2. **Phase 2**: Write `retry_test.go` with all test cases → implement `retry.go`  
3. **Phase 3**: Write `options.go` (structs only, no tests needed for data structures)
4. **Phase 4**: Write `hooks.go` (simple types, no complex logic)
5. **Phase 5**: Write `client_test.go` with all test cases → implement `client.go`
6. **Phase 6**: Integration tests using httpbin.org
7. **Phase 7**: Verify 95%+ coverage, race detector clean, go vet clean

## CRITICAL REQUIREMENTS
- ✅ Zero external dependencies (stdlib ONLY)
- ✅ 95%+ test coverage
- ✅ Thread-safe (verify with -race)
- ✅ Exponential backoff with jitter
- ✅ Retry on 429, 500, 502, 503, 504 ONLY
- ✅ Do NOT retry 400, 401, 403, 404
- ✅ Context cancellation support everywhere
- ✅ go vet clean, gofmt clean

## VALIDATION COMMANDS
Run these before marking complete:
```bash
go build ./internal/http
go test -v -coverprofile=coverage.out ./internal/http
go tool cover -func=coverage.out | grep total  # Must be 95%+
go test -race -v ./internal/http
go vet ./internal/http
gofmt -l ./internal/http  # Must return empty
```

## GIT WORKFLOW
Branch: `tier2/core-providers`
Commit after each phase with descriptive messages.

## WHEN BLOCKED
1. Read Go stdlib docs (net/http, time, context)
2. Web search for solutions
3. If stuck >30min → send message with details

## FINAL COMMIT MESSAGE TEMPLATE
```
feat(http): Complete HTTP foundation layer

✓ Connection pooling (100 idle, 10 per host)
✓ Retry with exponential backoff + jitter
✓ Rate limit header parsing (OpenAI/Anthropic/Google)
✓ Context propagation and cancellation
✓ API key sanitization in logs
✓ Hooks system for request/response interception
✓ 95%+ test coverage (actual: XX.X%)
✓ Thread-safe (race detector clean)
✓ Zero external dependencies

Tests:
- Unit: XX passing
- Integration: XX passing
- go vet: clean
- gofmt: clean

Lessons learned:
[Document any challenges, solutions, gotchas]
```

**Start coding now. You have complete clarity. Report progress every hour or when blocked.**

Begin implementing the feature now.